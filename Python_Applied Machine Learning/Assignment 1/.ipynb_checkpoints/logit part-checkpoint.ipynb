{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Dew point temperature(°C)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Functioning Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>37</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/12/2017</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Rented Bike Count  Hour  Temperature(°C)  Humidity(%)  \\\n",
       "0  01/12/2017                254     0             -5.2           37   \n",
       "1  01/12/2017                204     1             -5.5           38   \n",
       "\n",
       "   Wind speed (m/s)  Visibility (10m)  Dew point temperature(°C)  \\\n",
       "0               2.2              2000                      -17.6   \n",
       "1               0.8              2000                      -17.6   \n",
       "\n",
       "   Solar Radiation (MJ/m2)  Rainfall(mm)  Snowfall (cm) Seasons     Holiday  \\\n",
       "0                      0.0           0.0            0.0  Winter  No Holiday   \n",
       "1                      0.0           0.0            0.0  Winter  No Holiday   \n",
       "\n",
       "  Functioning Day  \n",
       "0             Yes  \n",
       "1             Yes  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2 = pd.read_csv(\"SeoulBikeData.csv\",encoding='latin1') \n",
    "dataset2.head(2) # view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2['Rented Bike Count'] = dataset2['Rented Bike Count'].astype(float)\n",
    "dataset2['Hour'] = dataset2['Hour'].astype(float)\n",
    "dataset2['Humidity(%)'] = dataset2['Humidity(%)'].astype(float)\n",
    "dataset2['Visibility (10m)'] = dataset2['Visibility (10m)'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                          object\n",
       "Rented Bike Count            float64\n",
       "Hour                         float64\n",
       "Temperature(°C)              float64\n",
       "Humidity(%)                  float64\n",
       "Wind speed (m/s)             float64\n",
       "Visibility (10m)             float64\n",
       "Dew point temperature(°C)    float64\n",
       "Solar Radiation (MJ/m2)      float64\n",
       "Rainfall(mm)                 float64\n",
       "Snowfall (cm)                float64\n",
       "Seasons                       object\n",
       "Holiday                       object\n",
       "Functioning Day               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[254.0 0.0 -5.2 ... 'Winter' 'No Holiday' 'Yes']\n",
      " [204.0 1.0 -5.5 ... 'Winter' 'No Holiday' 'Yes']\n",
      " [173.0 2.0 -6.0 ... 'Winter' 'No Holiday' 'Yes']\n",
      " ...\n",
      " [694.0 21.0 2.6 ... 'Autumn' 'No Holiday' 'Yes']\n",
      " [712.0 22.0 2.1 ... 'Autumn' 'No Holiday' 'Yes']\n",
      " [584.0 23.0 1.9 ... 'Autumn' 'No Holiday' 'Yes']]\n"
     ]
    }
   ],
   "source": [
    "# remove the date\n",
    "X_L= dataset2.iloc[:, 1:].values\n",
    "print(X_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 254.0 ... 0.0 'Winter' 'No Holiday']\n",
      " [0.0 1.0 204.0 ... 0.0 'Winter' 'No Holiday']\n",
      " [0.0 1.0 173.0 ... 0.0 'Winter' 'No Holiday']\n",
      " ...\n",
      " [0.0 1.0 694.0 ... 0.0 'Autumn' 'No Holiday']\n",
      " [0.0 1.0 712.0 ... 0.0 'Autumn' 'No Holiday']\n",
      " [0.0 1.0 584.0 ... 0.0 'Autumn' 'No Holiday']]\n"
     ]
    }
   ],
   "source": [
    "# Encoding the Independent Variable\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Encoding Functioning Day\n",
    "Functioning = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [-1])], remainder='passthrough')\n",
    "X_L = np.array(Functioning.fit_transform(X_L))\n",
    "print(X_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 0.0 ... 0.0 0.0 'No Holiday']\n",
      " [0.0 0.0 0.0 ... 0.0 0.0 'No Holiday']\n",
      " [0.0 0.0 0.0 ... 0.0 0.0 'No Holiday']\n",
      " ...\n",
      " [1.0 0.0 0.0 ... 0.0 0.0 'No Holiday']\n",
      " [1.0 0.0 0.0 ... 0.0 0.0 'No Holiday']\n",
      " [1.0 0.0 0.0 ... 0.0 0.0 'No Holiday']]\n"
     ]
    }
   ],
   "source": [
    "# Encoding seasons \n",
    "seasons = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [-2])], remainder='passthrough')\n",
    "X_L = np.array(seasons.fit_transform(X_L))\n",
    "print(X_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0 0.0 0.0 1.0 0.0 1.0 204.0 1.0 -5.5 38.0 0.8 2000.0 -17.6 0.0 0.0 0.0\n",
      " 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nimport collections, numpy\\nchek_H= X_L[:,-1]\\ncollections.Counter(chek_H)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding Holiday (No Holiday=0, Holiday = 1)\n",
    "for i in range(len(X_L)):\n",
    "  if X_L[i,-1] ==\"No Holiday\":\n",
    "     X_L[i,-1] = 0.0\n",
    "  else:\n",
    "    X_L[i,-1] = 1.0\n",
    "\n",
    "print(X_L[1])\n",
    "\"\"\"\n",
    "import collections, numpy\n",
    "chek_H= X_L[:,-1]\n",
    "collections.Counter(chek_H)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All number into float for further 'exp' caculation \n",
    "X_L = X_L[:, :-1]\n",
    "Y_L = X_L[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6132,) (6132, 16) (2628,) (2628, 16)\n"
     ]
    }
   ],
   "source": [
    "#Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_L, X_test_L, Y_train_L, Y_test_L = train_test_split(X_L, Y_L, test_size = 0.3, random_state = 1)\n",
    "print(Y_train_L.shape, X_train_L.shape, Y_test_L.shape, X_test_L.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just make the regression result more correctly, no need. \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_L = sc.fit_transform(X_train_L)\n",
    "X_test_L = sc.transform(X_test_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one\n",
    "X_train_L = np.concatenate((np.ones((len(X_train_L), 1)), X_train_L), axis=1)\n",
    "X_test_L = np.concatenate((np.ones((len(X_test_L), 1)), X_test_L), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.57483949 -0.57458841  1.72156931 -0.57910781 -0.18691364\n",
      "   0.18691364  0.2443009   0.79116445  1.03414826  1.40666502 -1.07006969\n",
      "  -1.13166338  1.43013904 -0.08175224 -0.13048284 -0.17682281]\n",
      " [ 1.         -0.57483949 -0.57458841  1.72156931 -0.57910781 -0.18691364\n",
      "   0.18691364 -0.05024993 -0.21523499  1.0424484   0.81681177 -0.97453415\n",
      "   0.92046118  1.25532504  0.46161113 -0.13048284 -0.17682281]]\n",
      "[[ 1.         -0.57483949  1.7403762  -0.58086537 -0.57910781 -0.18691364\n",
      "   0.18691364 -0.0132383  -0.50277769  0.44483842  0.22695851 -0.87899861\n",
      "   0.48496208  0.52566662  0.50785482 -0.13048284 -0.17682281]\n",
      " [ 1.          1.73961604 -0.57458841 -0.58086537 -0.57910781 -0.18691364\n",
      "   0.18691364  0.74549994 -0.35900634  0.88474577  0.66934845 -1.16560523\n",
      "   0.0791561   1.06530983  0.45005021 -0.13048284 -0.17682281]]\n",
      "[0.0 0.0]\n",
      "[0.0 0.0]\n",
      "(6132,) (6132, 17) (2628,) (2628, 17)\n"
     ]
    }
   ],
   "source": [
    "# CHECKING\n",
    "print(X_train_L[:2,:])\n",
    "print(X_test_L[:2,:])\n",
    "print(Y_train_L[0:2])\n",
    "print(Y_test_L[0:2])\n",
    "print(Y_train_L.shape, X_train_L.shape, Y_test_L.shape, X_test_L.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to float for exp caculation\n",
    "X_train_L = X_train_L.astype(float)\n",
    "X_test_L = X_test_L.astype(float)\n",
    "Y_train_L = Y_train_L.astype(float)\n",
    "Y_test_L = Y_test_L.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y_train_L , X_train_L, Y_test_L, X_test_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): #Hypothesis Values = y_hat\n",
    "    return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "def cost_funtion_L(X,Y,B):\n",
    "    ln = X.dot(B)\n",
    "    m = len(X)\n",
    "    h = sigmoid(ln)\n",
    "    cost = (np.log(h)@Y+np.log(1-h)@(1-Y))/(-m)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_gradient_descent(X, Y, B, alpha, iterations):\n",
    "    cost_history = [0] * iterations\n",
    "    ln_history = [0] * iterations\n",
    "    h_history = [0] * iterations\n",
    "    error_history = [0]*iterations\n",
    "    m = len(Y)\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        #print(iteration)\n",
    "        #Hypothesis Values = y_hat\n",
    "        ln = X.dot(B)\n",
    "        ln_history[iteration] = ln\n",
    "        h = sigmoid(ln)\n",
    "        h_history[iteration] = h\n",
    "        # Difference b/w Hypothesis and Actual Y\n",
    "        error = h-Y\n",
    "        error_history[iteration] = error\n",
    "        # Gradient Calculation\n",
    "        # gradient = X.T.dot(error) / m\n",
    "        # Changing Values of B using Gradient\n",
    "        B = B-alpha*X.T.dot(error)/m\n",
    "        # New Cost Value\n",
    "        cost = cost_funtion_L(X, Y, B)\n",
    "        cost_history[iteration] = cost\n",
    "\n",
    "    return B, cost_history, h_history, ln_history, error_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.37, -0.01, -0.03, -0.02,  0.07, -0.01,  0.01, -0.04, -0.  ,\n",
       "       -0.06,  0.04, -0.  , -0.04, -0.04, -0.02, -0.  ,  0.38])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.zeros(X_train_L.shape[1])\n",
    "iterations = 1000\n",
    "newB_L, cost_history_L,h_history, ln_history,error_history = L_gradient_descent(X_train_L,Y_train_L,B,0.001,iterations)\n",
    "#newB\n",
    "newB_L = np.around(newB_L, decimals=2)\n",
    "newB_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 is 90 and 0 is 2538\n",
      "[0 0 0 ... 1 0 0] (2628,) (2628,)\n"
     ]
    }
   ],
   "source": [
    "X_test_pred = X_test_L.dot(newB_L)\n",
    "X_test_pred = X_test_pred.tolist()\n",
    "qwe = len(X_test_pred)\n",
    "probability = []\n",
    "for i in range(qwe):\n",
    "    if X_test_pred[i] > 0.5:\n",
    "        probability.append(1)\n",
    "    else:\n",
    "        probability.append(0)\n",
    "\n",
    "print(\"1 is {} and 0 is {}\".format(probability.count(1),probability.count(0)))\n",
    "\n",
    "probability = np.asarray(probability)\n",
    "\n",
    "print( probability, probability.shape,Y_test_L.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2538   30    0    0    0    0    0    0    0]\n",
      " [   0   17    0    0    0    0    0    0    0]\n",
      " [   0   24    0    0    0    0    0    0    0]\n",
      " [   0   11    0    0    0    0    0    0    0]\n",
      " [   0    4    0    0    0    0    0    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0]\n",
      " [   0    1    0    0    0    0    0    0    0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9722222222222222"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "probability = probability.astype(int)\n",
    "Y_test_L = Y_test_L.astype(int)\n",
    "cm = confusion_matrix(Y_test_L, probability)\n",
    "print(cm)\n",
    "accuracy_score(Y_test_L, probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_history_L[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "ax.set_ylabel('J(Theta)')\n",
    "ax.set_xlabel('Iterations')\n",
    "_=ax.plot(range(iterations),cost_history_L,'b.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "ax.set_ylabel('h(x)')\n",
    "ax.set_xlabel('x')\n",
    "_=ax.plot(ln_history,h_history,'r.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
